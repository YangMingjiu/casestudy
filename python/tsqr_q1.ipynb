{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP55672: Case Studies in HPC\n",
    "## Case 1: Communication-Avoiding QR — Question 1\n",
    "### Mingjiu Yang\n",
    "### TSQR Factorisation (4-processor simulation in Python)\n",
    "\n",
    "This notebook implements the Tall-Skinny QR (TSQR) factorisation of a tall, narrow matrix $A \\in \\mathbb{R}^{m \\times n}$, $m \\gg n$, distributed across **4 processors** (simulated via row sub-indexing).\n",
    "\n",
    "---\n",
    "\n",
    "### Algorithm Overview\n",
    "\n",
    "**Level 0 — Local QR on each block:**\n",
    "$$A_i = Q_i^{(0)} R_i^{(0)}, \\quad i = 0, 1, 2, 3$$\n",
    "\n",
    "**Level 1 — Pairwise reduction (stack and QR):**\n",
    "$$\\begin{bmatrix} R_0^{(0)} \\\\ R_1^{(0)} \\end{bmatrix} = Q_{01}^{(1)} R_{01}^{(1)}, \\qquad \\begin{bmatrix} R_2^{(0)} \\\\ R_3^{(0)} \\end{bmatrix} = Q_{23}^{(1)} R_{23}^{(1)}$$\n",
    "\n",
    "**Level 2 — Final reduction:**\n",
    "$$\\begin{bmatrix} R_{01}^{(1)} \\\\ R_{23}^{(1)} \\end{bmatrix} = Q^{(2)} R$$\n",
    "\n",
    "The $R$ produced at Level 2 is the upper-triangular factor of the full QR decomposition of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24654b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import qr, norm\n",
    "\n",
    "np.random.seed(42)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4233a1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: TSQR Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4871da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsqr(A, num_procs=4, verbose=True):\n",
    "    \"\"\"\n",
    "    Communication-Avoiding TSQR factorisation.\n",
    "    Simulates distribution onto `num_procs` processors using row sub-indexing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A         : ndarray, shape (m, n), m >= n, m divisible by num_procs\n",
    "    num_procs : int, number of simulated processors (must be power of 2)\n",
    "    verbose   : bool, print intermediate shapes and residuals\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R_final : upper-triangular factor, shape (n, n)\n",
    "    Qs      : dict of all Q factors at each level (for full Q reconstruction)\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    assert m % num_procs == 0, \"m must be divisible by num_procs\"\n",
    "    assert m >= n, \"Matrix must be tall (m >= n)\"\n",
    "\n",
    "    block_size = m // num_procs  # rows per processor\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Level 0: Local QR on each processor block\n",
    "    # Each processor i owns rows [ i*block_size : (i+1)*block_size ]\n",
    "    # ----------------------------------------------------------------\n",
    "    if verbose:\n",
    "        print(\"=\" * 55)\n",
    "        print(f\"Input matrix A: {m} x {n}\")\n",
    "        print(f\"Block size per processor: {block_size} x {n}\")\n",
    "        print(\"=\" * 55)\n",
    "        print(\"\\n--- Level 0: Local QR on each block ---\")\n",
    "\n",
    "    Qs = {}          # store all Q factors\n",
    "    R_current = []   # R factors produced at this level\n",
    "\n",
    "    for i in range(num_procs):\n",
    "        row_start = i * block_size\n",
    "        row_end   = (i + 1) * block_size\n",
    "        A_block   = A[row_start:row_end, :]          # sub-indexing: rows of proc i\n",
    "\n",
    "        Q_i, R_i = qr(A_block)                      # local QR (numpy built-in)\n",
    "\n",
    "        Qs[(0, i)] = Q_i\n",
    "        R_current.append(R_i)                        # keep only R (n x n)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  Proc {i}: A[{row_start}:{row_end}, :] -> \"\n",
    "                  f\"Q shape {Q_i.shape}, R shape {R_i.shape}\")\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Reduction tree: log2(num_procs) levels\n",
    "    # At each level, pairs of R matrices are stacked and QR'd\n",
    "    # ----------------------------------------------------------------\n",
    "    level     = 1\n",
    "    active    = list(range(num_procs))  # active processor indices\n",
    "\n",
    "    while len(R_current) > 1:\n",
    "        if verbose:\n",
    "            print(f\"\\n--- Level {level}: Reduction ({len(R_current)} -> \"\n",
    "                  f\"{len(R_current)//2} R matrices) ---\")\n",
    "\n",
    "        R_next   = []\n",
    "        new_active = []\n",
    "\n",
    "        for j in range(0, len(R_current), 2):\n",
    "            # Stack two adjacent R matrices: shape (2n x n)\n",
    "            R_stacked = np.vstack([R_current[j], R_current[j + 1]])\n",
    "\n",
    "            Q_j, R_j = qr(R_stacked)               # QR of stacked R's\n",
    "\n",
    "            proc_id = active[j]                     # label by owning processor\n",
    "            Qs[(level, proc_id)] = Q_j\n",
    "            R_next.append(R_j)\n",
    "            new_active.append(proc_id)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"  Merge procs {active[j]},{active[j+1]}: \"\n",
    "                      f\"stacked shape {R_stacked.shape} -> \"\n",
    "                      f\"Q {Q_j.shape}, R {R_j.shape}\")\n",
    "\n",
    "        R_current = R_next\n",
    "        active    = new_active\n",
    "        level    += 1\n",
    "\n",
    "    R_final = R_current[0]   # upper-triangular factor of A\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n==> Final R shape: {R_final.shape}\")\n",
    "\n",
    "    return R_final, Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce02b78",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Correctness Verification\n",
    "\n",
    "We verify TSQR by checking two things:\n",
    "\n",
    "1. **R matches reference**: compare the absolute values of R from TSQR vs `numpy.linalg.qr(A)` directly (signs may differ due to Householder convention)\n",
    "2. **Residual** $\\|A - Q_{\\text{ref}} R_{\\text{TSQR}}\\|_F$: if R is correct, then $Q_{\\text{ref}} = A R^{-1}$ should be orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_tsqr(A, R_tsqr, verbose=True):\n",
    "    \"\"\"\n",
    "    Verify TSQR result against numpy's full QR as ground truth.\n",
    "\n",
    "    Checks:\n",
    "      (a) |R_tsqr| ≈ |R_ref|  (element-wise, sign-invariant)\n",
    "      (b) ||A - Q_ref R_tsqr||_F / ||A||_F  (relative residual)\n",
    "      (c) ||I - Q^T Q||_F  (orthogonality of Q_ref = A R_tsqr^{-1})\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "\n",
    "    # Reference QR from numpy\n",
    "    Q_ref, R_ref = qr(A, mode='reduced')   # Q: m x n, R: n x n\n",
    "\n",
    "    # (a) R comparison (sign-invariant)\n",
    "    R_diff = np.abs(R_tsqr) - np.abs(R_ref)\n",
    "    r_err  = norm(R_diff, 'fro') / norm(R_ref, 'fro')\n",
    "\n",
    "    # (b) Residual: reconstruct Q from A and R_tsqr via least squares\n",
    "    #     Q* = A R^{-1}  (since A = QR => Q = AR^{-1})\n",
    "    #     Use numpy solve for numerical stability\n",
    "    Q_tsqr = np.linalg.solve(R_tsqr.T, A.T).T  # A @ inv(R)\n",
    "    residual = norm(A - Q_tsqr @ R_tsqr, 'fro') / norm(A, 'fro')\n",
    "\n",
    "    # (c) Orthogonality of recovered Q\n",
    "    orth_err = norm(Q_tsqr.T @ Q_tsqr - np.eye(n), 'fro')\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Verification ===\")\n",
    "        print(f\"  Relative |R| difference vs numpy QR : {r_err:.2e}\")\n",
    "        print(f\"  Relative residual ||A - QR||/||A||  : {residual:.2e}\")\n",
    "        print(f\"  Orthogonality error ||I - Q^TQ||    : {orth_err:.2e}\")\n",
    "        tol = 1e-10\n",
    "        ok  = (r_err < tol) and (residual < tol) and (orth_err < tol)\n",
    "        print(f\"  PASS: {ok}\")\n",
    "\n",
    "    return r_err, residual, orth_err\n",
    "\n",
    "\n",
    "# --- Run a small concrete example ---\n",
    "m, n = 1200, 6    # tall-skinny: 1200 rows, 6 cols, 4 processors of 300 rows each\n",
    "A    = np.random.randn(m, n)\n",
    "\n",
    "R_tsqr, Qs = tsqr(A, num_procs=4, verbose=True)\n",
    "verify_tsqr(A, R_tsqr, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f29d1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Step-by-Step Walkthrough on a Tiny Matrix\n",
    "\n",
    "To make the linear algebra transparent, we trace through a $16 \\times 2$ example by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fdb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"Tiny example: A is 16 x 2, split into 4 blocks of 4 rows\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "A_tiny = np.random.randn(16, 2)\n",
    "\n",
    "# Level 0: local QR on each block\n",
    "blocks = [A_tiny[i*4:(i+1)*4, :] for i in range(4)]\n",
    "R0 = []\n",
    "for i, blk in enumerate(blocks):\n",
    "    Q_i, R_i = qr(blk)\n",
    "    R0.append(R_i)\n",
    "    print(f\"\\nProc {i}: A_block =\\n{np.round(blk,3)}\")\n",
    "    print(f\"  R_{i} =\\n{np.round(R_i,4)}\")\n",
    "\n",
    "# Level 1: merge (0,1) and (2,3)\n",
    "print(\"\\n--- Level 1 merge ---\")\n",
    "stacked_01 = np.vstack([R0[0], R0[1]])\n",
    "stacked_23 = np.vstack([R0[2], R0[3]])\n",
    "Q01, R01 = qr(stacked_01)\n",
    "Q23, R23 = qr(stacked_23)\n",
    "print(f\"Stack [R0;R1] -> R_01 =\\n{np.round(R01,4)}\")\n",
    "print(f\"Stack [R2;R3] -> R_23 =\\n{np.round(R23,4)}\")\n",
    "\n",
    "# Level 2: final merge\n",
    "print(\"\\n--- Level 2 merge (final) ---\")\n",
    "stacked_final = np.vstack([R01, R23])\n",
    "Q_final, R_final = qr(stacked_final)\n",
    "print(f\"Stack [R01;R23] -> R_final =\\n{np.round(R_final,4)}\")\n",
    "\n",
    "# Compare with numpy reference\n",
    "_, R_ref = qr(A_tiny, mode='reduced')\n",
    "print(f\"\\nnumpy reference R =\\n{np.round(R_ref,4)}\")\n",
    "print(f\"\\n|R_final| vs |R_ref| difference: {norm(np.abs(R_final)-np.abs(R_ref)):.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ymj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
